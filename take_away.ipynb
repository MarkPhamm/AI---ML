{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#-----------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format columns name\n",
    "def format_column_names(df):\n",
    "    \"\"\"\n",
    "    Format all column names in a DataFrame to snake_case.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): DataFrame whose column names are to be formatted.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with column names formatted to snake_case.\n",
    "    \"\"\"\n",
    "    formatted_columns = [col.replace(' ', '_').lower() for col in df.columns]\n",
    "    df.columns = formatted_columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda col: col.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Outlier\n",
    "def remove_outliers(df, column_names=None):\n",
    "    \"\"\"\n",
    "    Remove outliers from specific columns in the DataFrame based on the interquartile range (IQR) method,\n",
    "    or remove outliers from all numerical columns if column_names is None.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    - column_names: list or None, default None\n",
    "        The list of column names for which outliers are to be removed,\n",
    "        or None to remove outliers from all numerical columns.\n",
    "\n",
    "    Returns:\n",
    "    - df_filtered: DataFrame\n",
    "        The DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "    if column_names is None:\n",
    "        numerical_columns = df.select_dtypes(include='number').columns\n",
    "    else:\n",
    "        numerical_columns = column_names\n",
    "\n",
    "    total_removed = 0\n",
    "    total_rows = len(df)\n",
    "\n",
    "    for col in numerical_columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define the lower and upper bounds for outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Remove outliers from the specified column\n",
    "        removed_rows = len(df) - len(df[(df[col] >= lower_bound) & (df[col] <= upper_bound)])\n",
    "        total_removed += removed_rows\n",
    "\n",
    "        # Update DataFrame\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "        # Print the number and percentage of removed values if any rows have been removed\n",
    "        percentage_removed = (removed_rows / total_rows) * 100\n",
    "        print(f\"Removed {removed_rows} rows ({percentage_removed:.2f}%) due to outliers in column '{col}'.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataframe(df, columns_to_scale=None):\n",
    "    \"\"\"\n",
    "    Scale the specified columns in the DataFrame using Min-Max scaling.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): DataFrame to be scaled.\n",
    "        columns_to_scale (list): List of columns to be scaled. If None, scale all numerical columns.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Scaled DataFrame.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    if columns_to_scale is None:\n",
    "        columns_to_scale = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[columns_to_scale] = scaler.fit_transform(df_scaled[columns_to_scale])\n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['cash_advance_trx', 'tenure', 'full_payment']\n",
    "numerical_columns = [col for col in df.columns if col not in categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting subplots\n",
    "num_rows = 3\n",
    "num_cols = (len(numerical_columns) + len(categorical_columns) + num_rows - 1) // num_rows\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 10))\n",
    "\n",
    "for i, column in enumerate(numerical_columns):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    sns.histplot(df[column], ax=axes[row][col], kde=True)\n",
    "    axes[row][col].set_title(column)\n",
    "\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    row = (i + len(numerical_columns)) // num_cols\n",
    "    col = (i + len(numerical_columns)) % num_cols\n",
    "    sns.countplot(data=df, x=column, ax=axes[row][col])\n",
    "    axes[row][col].set_title(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 3\n",
    "num_cols = len(numerical_columns) // num_rows + (len(numerical_columns) % num_rows > 0)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(8 * num_cols, 6 * num_rows))\n",
    "axes = axes.ravel()  # Flatten the axes array\n",
    "\n",
    "for i, col in enumerate(numerical_columns):\n",
    "    ax = axes[i]\n",
    "    df.boxplot(column=col, ax=ax)\n",
    "    ax.set_title(f'Box plot for {col}')\n",
    "    ax.set_ylabel('Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[[numerical_columns]])\n",
    "plt.title('Pairplot of Numerical Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the number of clusters\n",
    "def calculate_inertia(df): \n",
    "    inertia_t = []\n",
    "    for i in range(1, 12):\n",
    "        km = KMeans(n_clusters=i).fit(df)\n",
    "        inertia_t.append(km.inertia_)\n",
    "\n",
    "    #Plot to check the suggested number of clusters\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.lineplot(x=range(1,12), y=inertia_t)\n",
    "    plt.title('KMeans inertia on transformed data')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_silhouette(df):\n",
    "    silhouette_scores = []\n",
    "    for i in range(2, 12):  # Considering clusters from 2 to 11\n",
    "        km = KMeans(n_clusters=i)\n",
    "        km.fit(df)\n",
    "        silhouette_scores.append(silhouette_score(df, km.labels_))\n",
    "\n",
    "    #Plot to check the suggested number of clusters\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.lineplot(x=range(2,12), y=silhouette_scores)\n",
    "    plt.title('KMeans silhouette scores on transformed data')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "def plot_acf_pacf(series, lags=None):\n",
    "    # Plot ACF\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plot_acf(series, lags=lags, ax=plt.gca())\n",
    "    plt.title('Autocorrelation Function (ACF)')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot PACF\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plot_pacf(series, lags=lags, ax=plt.gca())\n",
    "    plt.title('Partial Autocorrelation Function (PACF)')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('Partial Autocorrelation')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame and 'Oil' is the column you want to model\n",
    "plot_acf_pacf(df['Oil'], lags=30)  # You can adjust the number of lags as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differentiate_and_plot(series, diff_order):\n",
    "    # Differentiate the series the specified number of times\n",
    "    differentiated_series = series.diff(diff_order).dropna()\n",
    "    \n",
    "    # Plot the differentiated series\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(differentiated_series.index, differentiated_series.values, label=f'{diff_order}th Order Difference')\n",
    "    plt.title(f'{diff_order}th Order Difference of Time Series')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Perform ADF test to check stationarity\n",
    "    result = adfuller(differentiated_series)\n",
    "    print('ADF Statistic:', result[0])\n",
    "    print('p-value:', result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'   {key}: {value}')\n",
    "    if result[1] < 0.05:\n",
    "        print(\"The differentiated series is likely stationary (reject the null hypothesis)\")\n",
    "    else:\n",
    "        print(\"The differentiated series is likely non-stationary (fail to reject the null hypothesis)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arima_model(df, column_name, p, d, q):\n",
    "    # Convert the DataFrame column to a pandas Series\n",
    "    series = df[column_name]\n",
    "    \n",
    "    # Split the data into training and testing sets (80-20 split)\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    \n",
    "    # Fit ARIMA model\n",
    "    model = ARIMA(train, order=(p, d, q))\n",
    "    fitted_model = model.fit()\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = fitted_model.forecast(steps=len(test))\n",
    "    \n",
    "    # Visualize the training, testing, and predictions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train.index, train.values, label='Training Data')\n",
    "    plt.plot(test.index, test.values, label='Actual Test Data')\n",
    "    plt.plot(test.index, predictions, color='red', label='Predicted Test Data')\n",
    "    plt.title('ARIMA Model Predictions vs Actual')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    #Forecasting another 24 months \n",
    "    final_model = ARIMA(df, order=(p,d,q)).fit()\n",
    "    prediction=final_model.predict(len(df),len(df)+24)\n",
    "\n",
    "    df.plot(legend=True, label='Train', figsize=(10,6))\n",
    "    prediction.plot(legend=True, label='prediction')\n",
    "    \n",
    "    # Calculate and print RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(test, predictions))\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def differentiate_series(series, diff_order):\n",
    "    # Differentiate the series the specified number of times\n",
    "    differentiated_series = series.diff(diff_order).dropna()\n",
    "    return differentiated_series\n",
    "\n",
    "def create_ar_model(df, column_name, p, diff_order=0):\n",
    "    # Convert the DataFrame column to a pandas Series\n",
    "    series = df[column_name]\n",
    "    \n",
    "    # Plot the original series before differentiation\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(series.index, series.values, label='Original Data')\n",
    "    plt.title('Original Data')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Differentiate the series if diff_order is specified\n",
    "    if diff_order > 0:\n",
    "        differentiated_series = differentiate_series(series, diff_order)\n",
    "    else:\n",
    "        differentiated_series = series\n",
    "    \n",
    "    # Split the data into training and testing sets (80-20 split)\n",
    "    train_size = int(len(differentiated_series) * 0.8)\n",
    "    train, test = differentiated_series[:train_size], differentiated_series[train_size:]\n",
    "    \n",
    "    # Fit AR model\n",
    "    model_ar = AutoReg(train, lags=p)\n",
    "    fitted_model_ar = model_ar.fit()\n",
    "    \n",
    "    # Make predictions for differentiated series\n",
    "    predictions_ar_diff = fitted_model_ar.predict(start=len(train), end=len(train)+len(test)-1)\n",
    "    \n",
    "    # Visualize the training, testing, and predictions for differentiated series\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train.index, train.values, label='Training Data')\n",
    "    plt.plot(test.index, test.values, label='Actual Test Data')\n",
    "    plt.plot(test.index, predictions_ar_diff, color='blue', label='Predicted Test Data (AR)')\n",
    "    plt.title('AR Model Predictions vs Actual (Differentiated Series)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Forecasting another 24 months using AR for differentiated series\n",
    "    final_model_ar_diff = AutoReg(differentiated_series, lags=p).fit()\n",
    "    prediction_ar_diff = final_model_ar_diff.predict(start=differentiated_series.index[-1], end=differentiated_series.index[-1] + pd.DateOffset(months=24))\n",
    "\n",
    "    # Integrate the forecasted differentiated values into the original series\n",
    "    prediction_ar = series.iloc[-1] + np.cumsum(prediction_ar_diff)\n",
    "\n",
    "    # Plotting AR prediction for the next 24 months on the original series\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(series.index, series.values, label='Original Data')\n",
    "    plt.plot(prediction_ar.index, prediction_ar.values, color='purple', label='Forecast (AR)')\n",
    "    plt.title('AR Model Forecast for the Next 24 Months (Original Series)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate and print RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(test, predictions_ar_diff))\n",
    "    print(\"Root Mean Squared Error (RMSE) for differentiated series:\", rmse)\n",
    "\n",
    "    # Perform ADF test to check stationarity for differentiated series\n",
    "    result = adfuller(differentiated_series)\n",
    "    print('ADF Statistic for differentiated series:', result[0])\n",
    "    print('p-value for differentiated series:', result[1])\n",
    "    print('Critical Values for differentiated series:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'   {key}: {value}')\n",
    "    if result[1] < 0.05:\n",
    "        print(\"The differentiated series is likely stationary (reject the null hypothesis)\")\n",
    "    else:\n",
    "        print(\"The differentiated series is likely non-stationary (fail to reject the null hypothesis)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
